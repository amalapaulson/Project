{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NANFXPUPH5aK"
   },
   "source": [
    "# Understanding Latent Representations of Autoencoders\n",
    "\n",
    "### Loss Landscape\n",
    "    Loss landscape is a representation of loss values around the weight space. \n",
    "    We use two Random Directions(RD) vectors that are same size as weights of the autoencoder. \n",
    "    These RD compose a 2D plane in high dimensional space taking minimizer as reference point.\n",
    "On that 2D plane, we create a 9x9 grid and compute loss values for each grid points $(\\alpha,\\beta)$ to form a loss landscape.\n",
    "\n",
    "$$f({\\alpha},{\\beta})=L(\\theta^* + \\alpha\\delta + \\beta\\eta) \\text{, where }\\delta  \\text{ and } \\eta  \\text{ are random directions } $$\n",
    "    <img src=\"../random_directions.png\" height=\"200\" width=\"200\"/>\n",
    "      \n",
    "    \n",
    "In this experiment, we build a simple linear autoencoder having latent representation of size 8.\n",
    "We use each components of latent representation instead of loss values for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwJ0upxgH5aL"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGqPz4jGH5aZ"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8b66E4tMH5ag"
   },
   "outputs": [],
   "source": [
    "#visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker,colors\n",
    "%matplotlib inline\n",
    "from matplotlib.image import BboxImage\n",
    "from matplotlib.transforms import Bbox, TransformedBbox\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.layouts import row\n",
    "from bokeh.sampledata.iris import flowers\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.palettes import viridis\n",
    "from bokeh.palettes import brewer\n",
    "from bokeh.palettes import d3\n",
    "from bokeh.io import export_png\n",
    "from bokeh.models import Arrow, NormalHead, OpenHead, VeeHead\n",
    "\n",
    "\n",
    "output_notebook() # display plot in jupyter notebook when bokeh show() is called\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "haTOtGVxH5ak"
   },
   "outputs": [],
   "source": [
    "#k-means clustering\n",
    "\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVlIqVi4H5an"
   },
   "outputs": [],
   "source": [
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed) \n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "latent_size= 784 # change to get latent representation of different size\n",
    "startEpoch=0\n",
    "loadSavedModel=True \n",
    "saveModelDir=\"weights/\"\n",
    "weights=\"100_epoch.pth\" # 100_epoch.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDYZC3-cH5as"
   },
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = dsets.MNIST(root='../data',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_U5ZHL_H5ax"
   },
   "outputs": [],
   "source": [
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sl7OaPgzH5a6"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,latentSpaceSize=8,in_dim=784):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, latentSpaceSize),\n",
    "            nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latentSpaceSize, in_dim),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x) # Latent-space Representation\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        return encoded,decoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rdfrvJHH5a9"
   },
   "outputs": [],
   "source": [
    "ae = Autoencoder(latent_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    ae.cuda()\n",
    "\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(ae.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoJL2xNdH5bC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jS1ENFiH5bF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "cfLWMY_NH5bI",
    "outputId": "59138c5d-8aad-4ec5-b1d9-ebd90b7236b1"
   },
   "outputs": [],
   "source": [
    "if loadSavedModel:\n",
    "    model=saveModelDir+weights\n",
    "    if os.path.exists(model):\n",
    "        ae.load_state_dict(torch.load(model, map_location=lambda storage, loc: storage))\n",
    "        print('Pre-trained model is loaded:', weights)\n",
    "\n",
    "    startEpoch=int(weights.split(\"_\")[0])\n",
    "    \n",
    "    print(\"evaluating model..\")\n",
    "    encodedDict={}\n",
    "    labelDict={}\n",
    "    encodedList=[]\n",
    "    labelList=[]\n",
    "    with torch.no_grad(): # run the model at least once to load the latent representations for visualization\n",
    "        for i, (images, labels) in enumerate(data_loader):\n",
    "            img = to_var(images.view(images.size(0), -1))\n",
    "            encoded,decoded = ae(img)\n",
    "            loss = criterion(decoded, img)\n",
    "            encodedList.extend(encoded)\n",
    "            labelList.extend(labels.numpy())\n",
    "        encodedDict[startEpoch-1]=encodedList\n",
    "        labelDict[startEpoch-1]=labelList\n",
    "    print(\"compute latent representation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4R3in9ELH5bL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1QcqdAwH5bO"
   },
   "source": [
    "We train the autoencoder until the loss converges.\n",
    "We can save latent representation of each epoch and visualize how its latent landscape changes over each iteration.\n",
    "Following code only saves the latent representation of last epoch.\n",
    "\n",
    "For saving latent repr of all the epochs use\n",
    "```python\n",
    "encodedDict={}\n",
    "labelDict={}\n",
    "for epoch in range(num_epochs):\n",
    "    encodedList=[]\n",
    "    labelList=[]\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ADVSDdONH5bP",
    "outputId": "9831cc6b-f8cf-42f0-b90e-4ea8aeee0a65",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def checkpoint(epoch):\n",
    "    if not os.path.exists(saveModelDir):\n",
    "        os.mkdir(saveModelDir)\n",
    "        print(\"Directory \" , saveModelDir ,  \" Created \")\n",
    "        \n",
    "    model_out_path = saveModelDir+\"{}_epoch.pth\".format(epoch+1)\n",
    "    torch.save(ae.state_dict(), model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "    \n",
    "do = nn.Dropout()    \n",
    "for epoch in range(startEpoch,num_epochs):\n",
    "    encodedDict={}\n",
    "    labelDict={}\n",
    "    encodedList=[]\n",
    "    labelList=[]\n",
    "    training_loss = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        img = to_var(images.view(images.size(0), -1))\n",
    "        noise = to_var(do(torch.ones(img.shape)))\n",
    "        img_bad = to_var(img * noise)\n",
    "        encoded,decoded = ae(img_bad)\n",
    "        loss = criterion(decoded, img)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                %(epoch+1, num_epochs, i+1, len(dataset)//batch_size, loss.data))\n",
    "        encodedList.extend(encoded)\n",
    "        labelList.extend(labels.numpy())\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        checkpoint(epoch)\n",
    "    # compute the epoch training loss\n",
    "    training_loss = training_loss / len(data_loader)\n",
    "    # display the epoch average training loss\n",
    "    print(\"Epoch average training loss: {}/{}, loss = {:.6f}\".format(epoch + 1, num_epochs, training_loss))\n",
    "    encodedDict[epoch]=encodedList\n",
    "    labelDict[epoch]=labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FX0aBGClH5bT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4q_CujeH5bW"
   },
   "source": [
    "Here we trained our model and saved the latent space representation for plotting.\n",
    "We have 60000 training images and we have a latent space of size 8 per image. Hence we have a array of 60000*8 per epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5pPJZJZwH5bW"
   },
   "source": [
    "## PCA\n",
    "    PCA gives us direction of maximum variance and helps to project data into lower dimensions. We compute PCA and visualize the projected representation with a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tIV2TosCH5bX"
   },
   "outputs": [],
   "source": [
    "colormap={0:\"black\",1:\"silver\",2:\"red\",3:\"blue\",4:\"green\",5:\"yellow\",6:\"darkcyan\",7:\"yellowgreen\",8:\"royalblue\",9:\"purple\"}\n",
    "#colormap={i:v for i,v in enumerate(d3['Category10'][10])}\n",
    "colorLegend={0:\"0\",1:\"1\",2:\"2\",3:\"3\",4:\"4\",5:\"5\",6:\"6\",7:\"7\",8:\"8\",9:\"9\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "15vnw0HAH5ba",
    "outputId": "372fbce0-b0fa-40e1-e336-e57ed49a4d90"
   },
   "outputs": [],
   "source": [
    "#load 20000 data to the dataframe for plotting PCA and TSNE\n",
    "numRows = 20000\n",
    "df_oneThirdData = pd.DataFrame(encodedDict[num_epochs-1][0:numRows])\n",
    "pca = PCA()\n",
    "pca.fit(df_oneThirdData) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TeBEOBRdH5be"
   },
   "outputs": [],
   "source": [
    "def compute_pca(df):\n",
    "    pcaNewCoord = pca.transform(df)\n",
    "    pcaNewCoord = pd.DataFrame(pcaNewCoord)\n",
    "    return pcaNewCoord\n",
    "\n",
    "def plot_latent_space(newPCA1,newPCA2, rowCount):\n",
    "    colors = [colormap[x] for x in labelDict[num_epochs-1][0:rowCount]]\n",
    "    colorLegends=[colorLegend[x] for x in labelDict[num_epochs-1][0:rowCount]]\n",
    "\n",
    "    p = figure(title = \"MNIST\")\n",
    "    p.plot_width=800\n",
    "    p.xaxis.axis_label = 'PCA1'\n",
    "    p.yaxis.axis_label = 'PCA2'\n",
    "\n",
    "    source = ColumnDataSource({'x':newPCA1,'y':newPCA2,'colors':colors,'labels':colorLegends})\n",
    "    p.circle(x='x',y='y',color='colors', size=5,legend='labels',source=source)\n",
    "\n",
    "    p.legend.location = \"top_left\"\n",
    "    #output_file(\"PCA.html\", title=\"MNIST\")\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "colab_type": "code",
    "id": "u6XvnhQjH5bl",
    "outputId": "a44da691-bc02-4cbe-aee8-8ad6a50530e6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "newPCA=compute_pca(df_oneThirdData)\n",
    "plot_latent_space(newPCA[0],newPCA[1],numRows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUuWpg7bH5bt"
   },
   "source": [
    "## TSNE\n",
    "    PCA maintains the global structure of datapoints.\n",
    "    TSNE is a method for visualization where it maintains its local structure i.e distance between its 2 neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cq3UYoAYOkcz"
   },
   "outputs": [],
   "source": [
    "def compute_tsne(df):  \n",
    "    model = TSNE(n_components=2, random_state=0)\n",
    "    tsne_data = model.fit_transform(df)\n",
    "    tsne = pd.DataFrame(tsne_data)\n",
    "    return tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8i3I59-wOmvx"
   },
   "outputs": [],
   "source": [
    "tsne=compute_tsne(df_oneThirdData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "colab_type": "code",
    "id": "801i0HRBH5cJ",
    "outputId": "73dee2ca-3aa2-420a-ac77-c90b27381310"
   },
   "outputs": [],
   "source": [
    "plot_latent_space(tsne[0],tsne[1],numRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u8VvN-xyH5cN"
   },
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHGd4iKtPD-Y"
   },
   "outputs": [],
   "source": [
    "def KmeansFunction():\n",
    "    # define the model\n",
    "    model = KMeans(n_clusters=10, init='random', n_init=20, max_iter=300, tol=1e-04, random_state=0)\n",
    "    df_latent = df_oneThirdData\n",
    "    # assign a cluster to each example\n",
    "    y_kmeans = model.fit_predict(df_latent)\n",
    "    centroids = model.cluster_centers_\n",
    "    labelSet = model.labels_\n",
    "    return (df_latent, centroids, labelSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiFdpv0uP0NA"
   },
   "outputs": [],
   "source": [
    "# k-means clustering and then display using PCA\n",
    "\n",
    "def KmeansToPCA(df_latent, centroids, labelSet):\n",
    "\n",
    "    #compute the PCA for plotting\n",
    "\n",
    "    pcaNewCoord_latent = pca.transform(df_latent) \n",
    "    pcaNewCoord_latent = pd.DataFrame(pcaNewCoord_latent)\n",
    " \n",
    "    #compute the PCA of the centroids for plotting\n",
    "\n",
    "    df_centroids = pd.DataFrame(centroids)\n",
    "    pcaNewCoord_centroids = pca.transform(df_centroids) \n",
    "    pcaNewCoord_centroids = pd.DataFrame(pcaNewCoord_centroids)\n",
    "    \n",
    "    colors = [colormap[x] for x in labelSet]\n",
    "    \n",
    "    p = figure(title = \"MNIST with K Means Clustering\")\n",
    "    p.plot_width=800\n",
    "    p.xaxis.axis_label = 'PCA1'\n",
    "    p.yaxis.axis_label = 'PCA2'\n",
    "    source = ColumnDataSource({'x':pcaNewCoord_latent[0],'y':pcaNewCoord_latent[1],'colors':colors,'labels':labelSet})\n",
    "    p.circle(x='x',y='y',color='colors', size=5 ,source=source)\n",
    "\n",
    "    arrowDirection = 5\n",
    "    for i in range(10):\n",
    "        d = plot_linear_interpolations(i, centroids)\n",
    "        arrowDirection = -5 if arrowDirection == 5 else 5\n",
    "        coordXStart = pcaNewCoord_centroids[0][i] + arrowDirection\n",
    "        coordYStart = pcaNewCoord_centroids[1][i] + 5\n",
    "        coordXEnd = pcaNewCoord_centroids[0][i]\n",
    "        coordYEnd = pcaNewCoord_centroids[1][i]\n",
    "        img = np.flipud(d)\n",
    "        p.add_layout(Arrow(end=OpenHead(size=20, line_color=\"white\",line_width=2),line_color=\"white\",line_width=2,\n",
    "                   x_start=coordXStart, y_start=coordYStart, \n",
    "                           x_end=coordXEnd, y_end=coordYEnd))\n",
    "        p.image(image=[img], x=coordXStart, y=coordYStart, dw=1, dh=1, level=\"overlay\")\n",
    "\n",
    "    show(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_qZJ_LDP6j3"
   },
   "outputs": [],
   "source": [
    "# k-means clustering and then display using TSNE\n",
    "\n",
    "def KmeansToTSNE(df_latent, centroids, labelSet):\n",
    "    \n",
    "    #append the centroids to latent data set\n",
    "    \n",
    "    df_centroids = pd.DataFrame(centroids)\n",
    "    df_latent = df_latent.append(df_centroids)\n",
    "    \n",
    "    #compute the TSNE for plotting\n",
    "    tsne_latent=compute_tsne(df_latent)\n",
    "    tsne_coord = tsne_latent[0:20000]\n",
    "    tsne_centroids = tsne_latent[20000:20010]\n",
    "    tsne_centroids = tsne_centroids.to_numpy()\n",
    "\n",
    "    colors = [colormap[x] for x in labelSet]\n",
    "\n",
    "    p = figure(title = \"MNIST with K Means Clustering and display using TSNE\")\n",
    "    p.plot_width=800\n",
    "    p.xaxis.axis_label = 'PCA1'\n",
    "    p.yaxis.axis_label = 'PCA2'\n",
    "    source = ColumnDataSource({'x':tsne_coord[0],'y':tsne_coord[1],'colors':colors,'labels':labelSet})\n",
    "    p.circle(x='x',y='y',color='colors', size=5 ,source=source)\n",
    "    arrowDirection = 5\n",
    "    for i in range(10):\n",
    "        d = plot_linear_interpolations(i, centroids)\n",
    "        arrowDirection = -5 if arrowDirection == 5 else 5\n",
    "        coordXStart = tsne_centroids[i][0] + arrowDirection\n",
    "        coordYStart = tsne_centroids[i][1] + 5\n",
    "        coordXEnd = tsne_centroids[i][0]\n",
    "        coordYEnd = tsne_centroids[i][1]\n",
    "        img = np.flipud(d)\n",
    "        p.add_layout(Arrow(end=OpenHead(size=20, line_color=\"white\",line_width=2),line_color=\"white\",line_width=2,\n",
    "                   x_start=coordXStart, y_start=coordYStart, \n",
    "                           x_end=coordXEnd, y_end=coordYEnd))\n",
    "        p.image(image=[img], x=coordXStart, y=coordYStart, dw=5, dh=5, level=\"overlay\")\n",
    "\n",
    "    show(p)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KB3zMV4yH5cR"
   },
   "outputs": [],
   "source": [
    "def plot_linear_interpolations(index,centroids):\n",
    "    x = torch.tensor(centroids[index])\n",
    "    x = to_var(x)\n",
    "    img = ae.decoder(x.float())\n",
    "    img = img.cpu().detach().numpy()\n",
    "    return img.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TeFg4rxAQRyx",
    "outputId": "c4da010c-9f2f-415f-fedb-ca664823d779"
   },
   "outputs": [],
   "source": [
    "def plot_kmeans():\n",
    "    \n",
    "    (df_latent, centroids, labelSet) = KmeansFunction()\n",
    "    KmeansToPCA(df_latent, centroids, labelSet)\n",
    "    KmeansToTSNE(df_latent, centroids, labelSet)\n",
    "    \n",
    "plot_kmeans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ogQBBjMpH5cZ"
   },
   "source": [
    "## Filter Normalization\n",
    "\n",
    "The random direction is vector of same shape as weights of the network. The weights of random directions is a normal distribution. \n",
    "We normalize the weights of random directions such that the filter of each layers have same norm as the corresponding filters of autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SSXJytbEH5cZ"
   },
   "outputs": [],
   "source": [
    "t=torch.tensor(labelDict[num_epochs-1][0:numRows])\n",
    "\n",
    "indexOfDigits=[]\n",
    "eachDigitsPCA=[]\n",
    "for i in range(10):\n",
    "    eachDigit=(t == i).nonzero()\n",
    "    indexOfDigits.append(eachDigit.reshape(-1).tolist())\n",
    "    eachDigitsPCA.append(newPCA.iloc[indexOfDigits[i],0:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8aFmgP4H5cc"
   },
   "outputs": [],
   "source": [
    "#to visualize the historgram of weights (difference when filter normalization is applied)\n",
    "def viz_histogram_weights(converged_weights, direction1,direction2,title=\"None\"):\n",
    "    plt.figure(figsize=(55,55//9))\n",
    "    plt.suptitle(title, fontsize=20, y=1.15)\n",
    "    for layer_index in range(len(converged_weights)):\n",
    "        plt.subplot(2,8,layer_index+1)\n",
    "        plt.title(\"Layer : \" + str(layer_index))\n",
    "        plt.hist(converged_weights[layer_index].cpu().numpy().ravel(),50,alpha=0.6,label='Weight')\n",
    "        plt.hist(direction1[layer_index].cpu().numpy().ravel(),50,alpha=0.2,label='Direction 1')\n",
    "        plt.hist(direction2[layer_index].cpu().numpy().ravel(),50,alpha=0.2,label='Direction 2')\n",
    "        plt.yticks([])\n",
    "        plt.legend()\n",
    "        #plt.savefig(title+'.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zthj-2AyH5cf"
   },
   "outputs": [],
   "source": [
    "def get_weights(ae):\n",
    "    return [p.data for p in ae.parameters()]\n",
    "\n",
    "#normalizing weights of each layer of random direction with network weights w\n",
    "def get_random_weights(copy_of_the_weights):\n",
    "    direction=[]\n",
    "    for w in copy_of_the_weights:\n",
    "        random_vector = torch.randn(w.shape) \n",
    "        random_vector = random_vector * (w.norm()/(random_vector.norm()+1e-10))\n",
    "        direction.append(random_vector)\n",
    "    return direction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iM9MF9tCH5cm"
   },
   "outputs": [],
   "source": [
    "#normalizing weights of each filter of each layer of random direction with network weights w\n",
    "def get_random_weights_filter_norm(copy_of_the_weights):\n",
    "    direction=[]\n",
    "    for layer_weights in copy_of_the_weights:\n",
    "        randDir = torch.randn(layer_weights.shape) \n",
    "        for d, w in zip(randDir, layer_weights): \n",
    "            d.mul_(w.norm()/(d.norm() + 1e-10))\n",
    "        direction.append(randDir)  \n",
    "    \n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7teNZU-iH5cr"
   },
   "outputs": [],
   "source": [
    "weights=get_weights(ae)\n",
    "copy_of_the_weights = [ w.clone() for w in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "UZpdFPsgH5cv",
    "outputId": "e8e3e237-025f-49e0-d7df-32630e28a4f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display without normalization\n",
    "dir1=[torch.randn(w.size()) for w in copy_of_the_weights]\n",
    "dir2=[torch.randn(w.size()) for w in copy_of_the_weights]\n",
    "viz_histogram_weights(copy_of_the_weights,dir1,dir2,\"Random directions without filter normalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "id": "A_J9Hi8SH5c5",
    "outputId": "443fee4b-cb00-4d4a-8403-9aedd28d717b"
   },
   "outputs": [],
   "source": [
    "direction1=get_random_weights(copy_of_the_weights)\n",
    "direction2=get_random_weights(copy_of_the_weights)\n",
    "\n",
    "viz_histogram_weights(copy_of_the_weights,direction1,direction2,\"Random directions with layer normalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "id": "d4KddIEaH5c-",
    "outputId": "39fba4af-52dc-444b-b3ab-162751253bb1"
   },
   "outputs": [],
   "source": [
    "direction1=get_random_weights_filter_norm(copy_of_the_weights)\n",
    "direction2=get_random_weights_filter_norm(copy_of_the_weights)\n",
    "\n",
    "viz_histogram_weights(copy_of_the_weights,direction1,direction2,\"Random directions with filter normalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6fcZhnQeH5dC",
    "outputId": "894f4f51-1b2a-41fc-d5a3-025fbde12d25"
   },
   "outputs": [],
   "source": [
    "# create the coordinates \n",
    "number_of_points = 9 \n",
    "small_range = -1.0\n",
    "large_range =  1.0\n",
    "\n",
    "xcoordinates = np.linspace(small_range, large_range, num=number_of_points) \n",
    "ycoordinates = np.linspace(small_range, large_range, num=number_of_points) \n",
    "\n",
    "xcoord_mesh, ycoord_mesh = np.meshgrid(xcoordinates, ycoordinates)\n",
    "total_cordinates = np.array(range(number_of_points**2))\n",
    "alpha   = xcoord_mesh.ravel()[total_cordinates]\n",
    "beta   = ycoord_mesh.ravel()[total_cordinates]\n",
    "coordinate = np.c_[alpha,beta]\n",
    "print('From ',small_range,' to ',large_range,' with ',number_of_points,' total number of coordinate: ', number_of_points**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uzJom54QH5dI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44G2OglxH5dN"
   },
   "outputs": [],
   "source": [
    "def create_viz(loss_list,title=\"none\"):\n",
    "    \n",
    "    fig = go.Figure(data =\n",
    "        go.Contour(z=loss_list,x=xcoordinates,y=ycoordinates))\n",
    "    \n",
    "    fig.update_layout(height=400, width=500, title_text=\"Subplots\")\n",
    "    fig.show()\n",
    "    \n",
    "    data = [\n",
    "        go.Surface(\n",
    "            x=xcoord_mesh,y=ycoord_mesh,z=loss_list,colorscale='Jet',opacity=0.9,\n",
    "            contours=go.surface.Contours(z=go.surface.contours.Z(show=True,usecolormap=True,project=dict(z=True),),\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    layout = go.Layout(title='Loss',autosize=True,scene=dict(camera=dict(eye=dict(x=1.87, y=0.88, z=-0.64))),margin=dict(l=65,r=50,b=65,t=90))\n",
    "    fig    = go.Figure(data=data,layout=layout); \n",
    "    \n",
    "    fig.update_layout(height=400, width=600, title_text=\"Subplots\")\n",
    "    iplot(fig); \n",
    "    plt.show()\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnS-M4oPH5dQ"
   },
   "outputs": [],
   "source": [
    "dataset_eval = dsets.MNIST(root='../data',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "kmMkjIbpH5dc",
    "outputId": "057788c8-07e3-40bc-ee94-0af22a39c54a"
   },
   "outputs": [],
   "source": [
    "targetByDigits=[]\n",
    "dataByDigits=[]\n",
    "\n",
    "for i in range(10):\n",
    "    dataset_eval = dsets.MNIST(root='../data',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "    \n",
    "    labelIndex= dataset_eval.train_labels==i #get the index of digit i\n",
    "    targetByDigits.append(dataset_eval.train_labels[labelIndex]) \n",
    "    dataByDigits.append(dataset_eval.train_data[labelIndex]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cq2ioBPnH5dh"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lvp4nMfQH5di"
   },
   "source": [
    "## Loss landscape from latent representation of autoencoder\n",
    "\n",
    "For each digit in mnist dataset, there around 6-7 thousand dataset. We get same number of latent representation. To create a loss landscape, we can compute the mean value of all components in latent representation.\n",
    "    \n",
    "In our experiment, we took the mean of latent representation column wise for all datapoints of each digits. As an output we get 8 components in latent representation. We use each component to create a latent landscape.\n",
    "The same process is done for all 9x9=81 grid points. Hence we get 8 latent landscape.\n",
    "<img src=\"../loss_landscape_from_latentRepr.png\" height=\"400\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NqkwkKwTH5dj",
    "outputId": "54705036-de53-4031-fb38-a0e4769cf756"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ByPA0d41H5dq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#returns \n",
    "# 0:latentComponentsMean: mean of mean values taken columnwise, returns single value for each gridpoints\n",
    "# 1:latentComponents: mean taken columnwise, return 8 values for each gridpoints\n",
    "# 2:latentComponentsMeanL2: mean of L2 norm taken columnwise, returns single value for each gridpoints\n",
    "# 3:latentComponentsL2: L2 norm taken columnwise, return 8 values for each gridpoints\n",
    "\n",
    "def evalRandDirection(RD1,RD2):\n",
    "    \n",
    "    #for mean of 8 latent representation components\n",
    "    latentComponentsMean=np.zeros((number_of_points,number_of_points))\n",
    "\n",
    "    #for mean of the SD of 8 latent representation components\n",
    "    latentComponentsMeanofSD=np.zeros((number_of_points,number_of_points))\n",
    "    \n",
    "    # for each latent representation components\n",
    "    latentComponents={} \n",
    "    for m in range(latent_size):\n",
    "        latentComponents[m]=np.zeros((number_of_points,number_of_points))\n",
    "    \n",
    "    #for mean of 8 latent representation components\n",
    "    latentComponentsMeanL2=np.zeros((number_of_points,number_of_points))\n",
    "    \n",
    "    #L2for each latent representation components\n",
    "    latentComponentsL2={}\n",
    "    for n in range(latent_size):\n",
    "        latentComponentsL2[n]=np.zeros((number_of_points,number_of_points)) \n",
    "        \n",
    "    # SD for each latent representation components\n",
    "    latentComponentsSD={} \n",
    "    for m in range(latent_size):\n",
    "        latentComponentsSD[m]=np.zeros((number_of_points,number_of_points))\n",
    "   \n",
    "    col_value = 0\n",
    "    for index,_ in enumerate(total_cordinates):\n",
    "        alphaBeta=coordinate[index]\n",
    "        weightedRandomDirection= [d0*alphaBeta[0] + d1*alphaBeta[1] for (d0, d1) in zip(RD1,RD2)]\n",
    "        for (p, w, d) in zip(ae.parameters(), copy_of_the_weights, weightedRandomDirection):\n",
    "            p.data = w + to_var(d)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (images,labels) in enumerate(eval_data_loader):\n",
    "                #images = to_var(images)\n",
    "                images = to_var(images.view(images.size(0), -1))\n",
    "                latentspace,_ = ae(images) #Forward propagation\n",
    "                meanByLatentSize=latentspace.mean(axis=0) \n",
    "                SDByLatentSize = latentspace.std(axis=0)\n",
    "    \n",
    "                for j in range(latent_size):\n",
    "                    latentComponents[j][col_value,index%number_of_points]=meanByLatentSize[j]\n",
    "                \n",
    "                for j in range(latent_size):\n",
    "                    latentComponentsSD[j][col_value,index%number_of_points]=SDByLatentSize[j]\n",
    " \n",
    "                latentComponentsMean[col_value,index%number_of_points]=meanByLatentSize.mean()\n",
    "                latentComponentsMeanofSD[col_value,index%number_of_points]=SDByLatentSize.mean()\n",
    "                \n",
    "                L2norm=torch.norm(latentspace, dim=0)\n",
    "                for k in range(latent_size):\n",
    "                    latentComponentsL2[k][col_value,index%number_of_points]=L2norm[k]\n",
    "\n",
    "                latentComponentsMeanL2[col_value,index%number_of_points]=L2norm.mean()\n",
    "                \n",
    "                   \n",
    "                temp=index+1\n",
    "                if temp%number_of_points==0:\n",
    "                    col_value=col_value+1\n",
    "                break\n",
    "    \n",
    "    return latentComponentsMean,latentComponents,latentComponentsMeanL2,latentComponentsL2,latentComponentsSD,latentComponentsMeanofSD\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEF_R_EzH5dw"
   },
   "outputs": [],
   "source": [
    "def getMeanVector(typeofVector):\n",
    "    meanVector = np.zeros((1,10))\n",
    "    if typeofVector == 'mean':\n",
    "        j = 0\n",
    "    else:\n",
    "        j = 5\n",
    "    for i in range(10):\n",
    "        meanVector[0][i] = round(plotsByDigits[i][j].mean(), 2)\n",
    "        \n",
    "    return meanVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbZZqNNcH5d1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plots are saved in HTML format. You can hover over plots and get the coordinates,latent components value\n",
    "#https://plotly.com/python/interactive-html-export/\n",
    "    \n",
    "# orca can be used to save the plots in png or jpg format. \n",
    "#https://plotly.com/python/static-image-export/ \n",
    "\n",
    "\n",
    "\n",
    "def plotLatentLandscape(location,digits,data, typeofVector, zmaxColorBar ,zminColorBar):\n",
    "    fig = make_subplots(rows=2, cols=4)\n",
    "    for i in range(8):    \n",
    "        fig.add_trace(\n",
    "            go.Contour(z=data[i],x=xcoordinates,y=ycoordinates,\n",
    "                        contours=dict(\n",
    "                            start=zmaxColorBar,\n",
    "                            end= zminColorBar,\n",
    "                            size=0.5,\n",
    "                        ),),\n",
    "            row=i//4+1, col=i%4+1\n",
    "        )\n",
    "        fig.add_scatter(x=[0], y=[0], row=i//4+1, col=i%4+1, mode=\"markers\",\n",
    "                marker=dict(size=5, color=\"white\"),\n",
    "                name=\"centre\")\n",
    "        fig.update_layout(showlegend=False)\n",
    "\n",
    "    fig.update_layout(height=550, width=1000, title_text=\"Latent Landscape for digit \"+str(digits))\n",
    "    path=location+\"/digit_\"+str(digits)+\".html\"\n",
    "    fig.write_html(path)\n",
    "    fig.show()\n",
    "    print(\"Plot saved to: \", path)\n",
    "    \n",
    "    \n",
    "\n",
    "def plotlatentLandscapeMean(location,digits,data):\n",
    "    fig = go.Figure(data =\n",
    "    go.Contour(z=data,x=xcoordinates,y=ycoordinates))\n",
    "    fig.update_layout(height=400, width=500, title_text=\"Latent Landscape for digit \"+str(digits))\n",
    "    path=location+\"/digit_\"+str(digits)+\".html\"\n",
    "    fig.write_html(path)\n",
    "    \n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "RW0u1qAxH5eA",
    "outputId": "072bf41d-0b8e-4f27-bc50-dbb1101b0be5"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "direction1=get_random_weights_filter_norm(copy_of_the_weights)\n",
    "direction2=get_random_weights_filter_norm(copy_of_the_weights)\n",
    "plotsByDigits=[]\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"computing latent landscape for digit: \",i)\n",
    "    dataset_eval.targets = targetByDigits[i]\n",
    "    dataset_eval.data = dataByDigits[i]\n",
    "    eval_data_loader = torch.utils.data.DataLoader(dataset=dataset_eval,batch_size=60000,shuffle=True)\n",
    "    plotsByDigits.append(evalRandDirection(direction1,direction2))\n",
    "    print(\"Done\")\n",
    "\n",
    "with open('plotsByDigits.pkl', 'wb') as f:\n",
    "    pickle.dump(plotsByDigits, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWKBleqMH5eL",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DiJVW3zKH5eU"
   },
   "source": [
    "Selected images of only one label.\n",
    "E.g. we have 7000 images of ones, then we have (7000x8) latent representation.\n",
    "take each component for plotting the loss landscapes\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UcXg7UCZH5eV"
   },
   "outputs": [],
   "source": [
    "with open('plotsByDigits.pkl', 'rb') as f:\n",
    "    plotsByDigits = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0SJ1IaF9kyM"
   },
   "outputs": [],
   "source": [
    "def getMinMaxValue(zValues, typeOfData):\n",
    "    zmaxList = []\n",
    "    zminList = []\n",
    "    for i in range(10):\n",
    "        zmaxList.append(np.amax(np.array(list(plotsByDigits[i][typeOfData].values()))))\n",
    "        zminList.append(np.amin(np.array(list(plotsByDigits[i][typeOfData].values()))))\n",
    "    zmax = np.amax(zmaxList)\n",
    "    zmin = np.amin(zminList)\n",
    "    return (zmax,zmin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LBU1LvylrbY"
   },
   "outputs": [],
   "source": [
    "def computePCALatentLandscape(dataToCompute):\n",
    "  dataForPCA = pd.DataFrame() \n",
    "  for i in range(len(dataToCompute)):\n",
    "    dataForPCA = dataForPCA.append(pd.DataFrame(dataToCompute[i].reshape(1,81)), ignore_index = True)\n",
    "  pcaCoord = compute_pca(dataForPCA.T)\n",
    "  return pcaCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "N7OdccNfH5eg",
    "outputId": "b282bcb2-067f-48a1-b6eb-6375a2739894"
   },
   "outputs": [],
   "source": [
    "plotLocation=\"latentLanscapes_seed0\"\n",
    "\n",
    "if not os.path.exists(plotLocation):\n",
    "    os.mkdir(plotLocation)\n",
    "(zmax,zmin) = getMinMaxValue(plotsByDigits, 1)\n",
    "for i in range(10):\n",
    "    PCAToPlot = computePCALatentLandscape(plotsByDigits[i][1])\n",
    "    plotLatentLandscape(plotLocation,i,PCAToPlot, 'mean', zmax,zmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5uKY3pHeH5e1",
    "outputId": "795eec30-7306-455d-9f4f-83ce567bc33d"
   },
   "outputs": [],
   "source": [
    "plotLocation=\"latentLanscapes_seed0_SD\"\n",
    "if not os.path.exists(plotLocation):\n",
    "    os.mkdir(plotLocation)\n",
    "(zmax,zmin) = getMinMaxValue(plotsByDigits, 4)\n",
    "for i in range(10):\n",
    "    PCAToPlot = computePCALatentLandscape(plotsByDigits[i][4])\n",
    "    plotLatentLandscape(plotLocation,i,PCAToPlot, 'sd', zmax,zmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQoAqElqH5fg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "RUuWpg7bH5bt"
   ],
   "name": "latent_repr_relu-overcomplete.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
