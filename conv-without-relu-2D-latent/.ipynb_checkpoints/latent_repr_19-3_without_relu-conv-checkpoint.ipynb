{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                               Anuj Maharjan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Latent Representations of Autoencoders\n",
    "\n",
    "### Loss Landscape\n",
    "    Loss landscape is a representation of loss values around the weight space. \n",
    "    We use two Random Directions(RD) vectors that are same size as weights of the autoencoder. \n",
    "    These RD compose a 2D plane in high dimensional space taking minimizer as reference point.\n",
    "   On that 2D plane, we create a 9x9 grid and compute loss values for each grid points $(\\alpha,\\beta)$ to form a loss landscape.\n",
    "\n",
    "$$f({\\alpha},{\\beta})=L(\\theta^* + \\alpha\\delta + \\beta\\eta) \\text{, where }\\delta  \\text{ and } \\eta  \\text{ are random directions } $$\n",
    "    <img src=\"../random_directions\" height=\"200\" width=\"200\"/>\n",
    "      \n",
    "    \n",
    "In this experiment, we build a simple conv autoencoder having latent representation of size 8.\n",
    "We use each components of latent representation instead of loss values for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from time import time\n",
    "#!{sys.executable} -m pip install torchsummary plotly\n",
    "#similarily install all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /home/anuj/anaconda3/lib/python3.7/site-packages (3.141.0)\r\n",
      "Requirement already satisfied: urllib3 in /home/anuj/anaconda3/lib/python3.7/site-packages (from selenium) (1.24.2)\r\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker,colors\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.layouts import row\n",
    "from bokeh.sampledata.iris import flowers\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.palettes import viridis\n",
    "from bokeh.palettes import brewer\n",
    "from bokeh.palettes import d3\n",
    "from bokeh.io import export_png\n",
    "\n",
    "\n",
    "output_notebook() # display plot in jupyter notebook when bokeh show() is called\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 1\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "latent_size=8 # change to get latent representation of different size\n",
    "\n",
    "loadSavedModel=True # 100_epoch.pth\n",
    "startEpoch=0\n",
    "saveModelDir=\"weights/\"\n",
    "\n",
    "\n",
    "#loading the last saved model\n",
    "if loadSavedModel:\n",
    "    list_of_files = glob.glob(\"weights/*\")\n",
    "    if len(list_of_files)!=0:\n",
    "        latest_weights = max(list_of_files, key=os.path.getctime)\n",
    "        weights=os.path.basename(latest_weights)\n",
    "        \n",
    "        startEpoch=int(weights.split(\"_\")[0])-1  \n",
    "print(\"Starting Epoch:\",startEpoch+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = dsets.MNIST(root='../data',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,latentSpaceSize=8,in_dim=784):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latentSpaceSize=latentSpaceSize\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.encoderLin=nn.Sequential(\n",
    "            nn.Linear(64,latentSpaceSize)\n",
    "        )\n",
    "   \n",
    "        self.decoderLin=nn.Sequential(\n",
    "            nn.Linear(latentSpaceSize,64)\n",
    "        )\n",
    "    \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        elatent = self.encoder(x)\n",
    "        flattened=elatent.view(elatent.size(0), -1)\n",
    "        encoded=self.encoderLin(flattened)\n",
    "        \n",
    "        dLatent=self.decoderLin(encoded)\n",
    "        convDim=dLatent.reshape(dLatent.size(0),64,1,1)\n",
    "        decoded = self.decoder(convDim)\n",
    "        \n",
    "        return encoded,decoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = Autoencoder(latent_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    ae.cuda()\n",
    "\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(ae.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae = Autoencoder(latent_size)\n",
    "#ae.load_state_dict(torch.load(\"model200_conv_relu_16-3.pth\"))\n",
    "#ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadSavedModel:\n",
    "    list_of_files = glob.glob(\"weights/*\")\n",
    "    if len(list_of_files)!=0:\n",
    "        model_name = os.path.join(saveModelDir + weights)\n",
    "        if os.path.exists(model_name):\n",
    "            ae.load_state_dict(torch.load(model_name, map_location=lambda storage, loc: storage))\n",
    "            print('Pre-trained model is loaded:', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if loading the last model, evaluate the model to accumlate latent representation\n",
    "\n",
    "if startEpoch+1 == num_epochs:\n",
    "    print(\"evaluating model..\")\n",
    "\n",
    "    encodedDict={}\n",
    "    labelDict={}\n",
    "    encodedList=[]\n",
    "    labelList=[]\n",
    "    with torch.no_grad(): # run the model at least once to load the latent representations for visualization\n",
    "        for i, (images, labels) in enumerate(data_loader):\n",
    "            img = to_var(images)\n",
    "            encoded,decoded = ae(img)\n",
    "            loss = criterion(decoded, img)\n",
    "\n",
    "            encodedList.extend(encoded)\n",
    "            labelList.extend(labels.numpy())\n",
    "        encodedDict[epoch]=encodedList\n",
    "        labelDict[epoch]=labelList\n",
    "    print(\"compute latent representation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the autoencoder until the loss converges.\n",
    "We can save latent representation in each epoch and visualize it how the loss landscape changes over each iteration.\n",
    "Following code only saves the latent representation of last epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Iter [100/600] Loss: 0.0667\n",
      "Epoch [1/100], Iter [200/600] Loss: 0.0617\n",
      "Epoch [1/100], Iter [300/600] Loss: 0.0449\n",
      "Epoch [1/100], Iter [400/600] Loss: 0.0323\n",
      "Epoch [1/100], Iter [500/600] Loss: 0.0286\n",
      "Epoch [1/100], Iter [600/600] Loss: 0.0261\n"
     ]
    }
   ],
   "source": [
    "def checkpoint(epoch):\n",
    "    if not os.path.exists(saveModelDir):\n",
    "        os.mkdir(saveModelDir)\n",
    "        print(\"Directory \" , saveModelDir ,  \" Created \")\n",
    "        \n",
    "    model_out_path = saveModelDir+\"{}_epoch.pth\".format(epoch+1)\n",
    "    torch.save(ae.state_dict(), model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    encodedDict={}\n",
    "    labelDict={}\n",
    "    encodedList=[]\n",
    "    labelList=[]\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        img = to_var(images)\n",
    "        encoded,decoded = ae(img)\n",
    "        loss = criterion(decoded, img)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                %(epoch+1, num_epochs, i+1, len(dataset)//batch_size, loss.data))\n",
    "        encodedList.extend(encoded)\n",
    "        labelList.extend(labels.numpy())\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        checkpoint(epoch)\n",
    "    encodedDict[epoch]=encodedList\n",
    "    labelDict[epoch]=labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we trained our model and saved the latent space representation for plotting.\n",
    "We have 60000 training images and we have a latent space of size 8 per image. Hence we have a array of 60000*8 per epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "    PCA gives us direction of maximum variance and helps to project data into lower dimensions. We compute PCA and visualize the projected representation with a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap={0:\"black\",1:\"silver\",2:\"red\",3:\"blue\",4:\"green\",5:\"yellow\",6:\"darkcyan\",7:\"yellowgreen\",8:\"royalblue\",9:\"purple\"}\n",
    "#colormap={i:v for i,v in enumerate(d3['Category10'][10])}\n",
    "colorLegend={0:\"0\",1:\"1\",2:\"2\",3:\"3\",4:\"4\",5:\"5\",6:\"6\",7:\"7\",8:\"8\",9:\"9\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brewer['Paired'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viridis(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this flattens the latent representation when linear layer not used after encoder.\n",
    "```python\n",
    "flattenLatentSpace={}\n",
    "for k, v in encodedDict.items():\n",
    "    temp=[]\n",
    "    for t in v:\n",
    "        temp.append(t.reshape(-1))\n",
    "    flattenLatentSpace[k]=temp\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pca(plot_epoch):\n",
    "    df = pd.DataFrame(encodedDict[plot_epoch])\n",
    "    pca = PCA()\n",
    "\n",
    "    pcaNewCoord = pca.fit_transform(df) \n",
    "    pcaNewCoord = pd.DataFrame(pcaNewCoord)\n",
    "    return pcaNewCoord\n",
    "\n",
    "def plot_latent_space(newPCA1,newPCA2,plot_epoch):\n",
    "    colors = [colormap[x] for x in labelDict[plot_epoch]]\n",
    "    colorLegends=[colorLegend[x] for x in labelDict[plot_epoch]]\n",
    "\n",
    "    p = figure(title = \"MNIST\")\n",
    "    p.plot_width=800\n",
    "    p.xaxis.axis_label = 'PCA1'\n",
    "    p.yaxis.axis_label = 'PCA2'\n",
    "\n",
    "    source = ColumnDataSource({'x':newPCA1,'y':newPCA2,'colors':colors,'labels':colorLegends})\n",
    "    p.circle(x='x',y='y',color='colors', size=5,legend='labels',source=source)\n",
    "\n",
    "    p.legend.location = \"top_left\"\n",
    "    output_file(\"PCA.html\", title=\"MNIST\")\n",
    "    \n",
    "    show(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "newPCA=compute_pca(num_epochs-1)\n",
    "plot_latent_space(newPCA[0],newPCA[1],num_epochs-1)\n",
    "\n",
    "#plot for all epochs\n",
    "#for i in range(num_epochs):\n",
    "#    plot_latent_space(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_latent_space(newPCA[0],newPCA[2],num_epochs-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE\n",
    "    PCA maintains the global structure of datapoints.\n",
    "    TSNE is a method for visualization where it maintains its local structure i.e distance between its 2 neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tsne(plot_epoch):\n",
    "    df = pd.DataFrame(encodedDict[plot_epoch])\n",
    "    model = TSNE(n_components=2, random_state=0)\n",
    "    tsne_data = model.fit_transform(df)\n",
    "    tsne = pd.DataFrame(tsne_data)\n",
    "    \n",
    "    return tsne\n",
    "\n",
    "\n",
    "tsne=compute_tsne(num_epochs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute tsne or load the from saved pickle file\n",
    "\n",
    "tsne.to_pickle(\"./tsne.pkl\")\n",
    "tsne=pd.read_pickle(\"./tsne.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_space(tsne[0],tsne[1],num_epochs-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting each digits seperately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.tensor(labelDict[num_epochs-1])\n",
    "indexOfDigits=[]\n",
    "eachDigitsPCA=[]\n",
    "for i in range(10):\n",
    "    eachDigit=(t == i).nonzero()\n",
    "    indexOfDigits.append(eachDigit.reshape(-1).tolist())\n",
    "    eachDigitsPCA.append(newPCA.iloc[indexOfDigits[i],0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space_label(eachDigitsPCA,indexOfDigits):\n",
    "    fig=[]\n",
    "    for i in range(10):\n",
    "        colors = [colormap[i] for x in range(len(indexOfDigits[i]))]\n",
    "        colorLegends=[colorLegend[i] for x in range(len(indexOfDigits[i]))]\n",
    "        p = figure(title = \"MNIST\")\n",
    "        p.plot_width=200\n",
    "        p.plot_height=200\n",
    "        \n",
    "        p.xaxis.axis_label = 'PCA1'\n",
    "        p.yaxis.axis_label = 'PCA2'\n",
    "\n",
    "        source = ColumnDataSource({'x':eachDigitsPCA[i][0],'y':eachDigitsPCA[i][1],'colors':colors,'labels':colorLegends})\n",
    "        p.circle(x='x',y='y',color='colors', size=5,legend='labels',source=source)\n",
    "        p.legend.location = \"top_left\"\n",
    "        p.legend.glyph_height = 10\n",
    "        p.legend.glyph_width = 10\n",
    "        fig.append(p)\n",
    "        \n",
    "    show(row(fig[0],fig[1],fig[2],fig[3],fig[4]))\n",
    "    show(row(fig[5],fig[6],fig[7],fig[8],fig[9]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_latent_space_label(eachDigitsPCA,indexOfDigits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Normalization\n",
    "\n",
    "The random direction is vector of same shape as weights of the network. The weights of random directions is a normal distribution. \n",
    "We normalize the weights of random directions such that the filter of each layers have same norm as the corresponding filters of autoencoder.\n",
    "Also, we can normalize such that each layer of random direction has same norm as the layers of autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to visualize the historgram of weights (difference when filter normalization is applied)\n",
    "def viz_histogram_weights(converged_weights, direction1,direction2,title=\"None\"):\n",
    "    plt.figure(figsize=(55,55//9))\n",
    "    plt.suptitle(title, fontsize=20, y=1.15)\n",
    "    for layer_index in range(len(converged_weights)):\n",
    "        plt.subplot(2,8,layer_index+1)\n",
    "        plt.title(\"Layer : \" + str(layer_index))\n",
    "        plt.hist(converged_weights[layer_index].cpu().numpy().ravel(),50,alpha=0.6,label='Weight')\n",
    "        plt.hist(direction1[layer_index].cpu().numpy().ravel(),50,alpha=0.2,label='Direction 1')\n",
    "        plt.hist(direction2[layer_index].cpu().numpy().ravel(),50,alpha=0.2,label='Direction 2')\n",
    "        plt.yticks([])\n",
    "        plt.legend()\n",
    "        plt.savefig(title+'.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(ae):\n",
    "    return [p.data for p in ae.parameters()]\n",
    "\n",
    "#normalizing weights of each layer of random direction with network weights w\n",
    "def get_random_weights(copy_of_the_weights):\n",
    "    direction=[]\n",
    "    for w in copy_of_the_weights:\n",
    "        random_vector = torch.randn(w.shape) \n",
    "        random_vector = random_vector * (w.norm()/(random_vector.norm()+1e-10))\n",
    "        direction.append(random_vector)\n",
    "    return direction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing weights of each filter of each layer of random direction with network weights w\n",
    "def get_random_weights_filter_norm(copy_of_the_weights):\n",
    "    direction=[]\n",
    "    for layer_weights in copy_of_the_weights:\n",
    "        randDir = torch.randn(layer_weights.shape) \n",
    "        for d, w in zip(randDir, layer_weights): \n",
    "            d.mul_(w.norm()/(d.norm() + 1e-10))\n",
    "        direction.append(randDir)  \n",
    "    \n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=get_weights(ae)\n",
    "copy_of_the_weights = [ w.clone() for w in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display without normalization\n",
    "dir1=[torch.randn(w.size()) for w in copy_of_the_weights]\n",
    "dir2=[torch.randn(w.size()) for w in copy_of_the_weights]\n",
    "\n",
    "viz_histogram_weights(copy_of_the_weights,dir1,dir2,\"Random directions without filter normalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction1=get_random_weights(copy_of_the_weights)\n",
    "direction2=get_random_weights(copy_of_the_weights)\n",
    "\n",
    "viz_histogram_weights(copy_of_the_weights,direction1,direction2,\"Random directions with layer normalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction1=get_random_weights_filter_norm(copy_of_the_weights)\n",
    "direction2=get_random_weights_filter_norm(copy_of_the_weights)\n",
    "\n",
    "viz_histogram_weights(copy_of_the_weights,direction1,direction2,\"Random directions with filter normalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the coordinates \n",
    "number_of_points = 9 \n",
    "small_range = -1.0\n",
    "large_range =  1.0\n",
    "\n",
    "xcoordinates = np.linspace(small_range, large_range, num=number_of_points) \n",
    "ycoordinates = np.linspace(small_range, large_range, num=number_of_points) \n",
    "\n",
    "xcoord_mesh, ycoord_mesh = np.meshgrid(xcoordinates, ycoordinates)\n",
    "total_cordinates = np.array(range(number_of_points**2))\n",
    "alpha   = xcoord_mesh.ravel()[total_cordinates]\n",
    "beta   = ycoord_mesh.ravel()[total_cordinates]\n",
    "coordinate = np.c_[alpha,beta]\n",
    "print('From ',small_range,' to ',large_range,' with ',number_of_points,' total number of coordinate: ', number_of_points**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_viz(loss_list,title=\"none\"):\n",
    "    \n",
    "    fig = go.Figure(data =\n",
    "        go.Contour(z=loss_list,x=xcoordinates,y=ycoordinates))\n",
    "    \n",
    "    fig.update_layout(height=400, width=500, title_text=\"Subplots\")\n",
    "    fig.show()\n",
    "    \n",
    "    data = [\n",
    "        go.Surface(\n",
    "            x=xcoord_mesh,y=ycoord_mesh,z=loss_list,colorscale='Jet',opacity=0.9,\n",
    "            contours=go.surface.Contours(z=go.surface.contours.Z(show=True,usecolormap=True,project=dict(z=True),),\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    layout = go.Layout(title='Loss',autosize=True,scene=dict(camera=dict(eye=dict(x=1.87, y=0.88, z=-0.64))),margin=dict(l=65,r=50,b=65,t=90))\n",
    "    fig    = go.Figure(data=data,layout=layout); \n",
    "    \n",
    "    fig.update_layout(height=400, width=600, title_text=\"Subplots\")\n",
    "    iplot(fig); \n",
    "    plt.show()\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval = dsets.MNIST(root='../data',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetByDigits=[]\n",
    "dataByDigits=[]\n",
    "\n",
    "for i in range(10):\n",
    "    dataset_eval = dsets.MNIST(root='../data',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "    \n",
    "    labelIndex= dataset_eval.train_labels==i #get the index of digit i\n",
    "    targetByDigits.append(dataset_eval.train_labels[labelIndex]) \n",
    "    dataByDigits.append(dataset_eval.train_data[labelIndex]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss landscape from latent representation of autoencoder\n",
    "\n",
    "For each digit in mnist dataset, there around 6-7 thousand dataset. We get same number of latent representation. To create a loss landscape, we can compute the mean value of all components in latent representation.\n",
    "    \n",
    "In our experiment, we took the mean of latent representation column wise for all datapoints of each digits. As an output we get 8 components in latent representation. We use each component to create a loss landscape.\n",
    "The same process is done for all 9x9=81 grid points. Hence we get 8 loss landscape.\n",
    "\n",
    "<img src=\"../loss_landscape_from_latentRepr.png\" height=\"400\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected images of only one label.\n",
    "E.g. we have 7000 images of ones, then we have (7000x8) latent representation.\n",
    "take each component for plotting the loss landscapes\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#returns \n",
    "# 0:latentComponentsMean: mean of mean values taken columnwise, returns single value for each gridpoints\n",
    "# 1:latentComponents: mean taken columnwise, return 8 values for each gridpoints\n",
    "# 2:latentComponentsMeanL2: mean of L2 norm taken columnwise, returns single value for each gridpoints\n",
    "# 3:latentComponentsL2: L2 norm taken columnwise, return 8 values for each gridpoints\n",
    "\n",
    "def evalRandDirection(RD1,RD2):\n",
    "    \n",
    "    #for mean of 8 latent representation components\n",
    "    latentComponentsMeanLoss=np.zeros((number_of_points,number_of_points))\n",
    "    \n",
    "    # for each latent representation components\n",
    "    latentComponentsLoss={}\n",
    "    for m in range(latent_size):\n",
    "        latentComponentsLoss[m]=np.zeros((number_of_points,number_of_points))\n",
    "    \n",
    "    #for mean of 8 latent representation components\n",
    "    latentComponentsMeanLossL2=np.zeros((number_of_points,number_of_points))\n",
    "    \n",
    "    #L2for each latent representation components\n",
    "    latentComponentsLossL2={}\n",
    "    for n in range(latent_size):\n",
    "        latentComponentsLossL2[n]=np.zeros((number_of_points,number_of_points)) \n",
    "   \n",
    "    col_value = 0\n",
    "    for index,_ in enumerate(total_cordinates):\n",
    "        alphaBeta=coordinate[index]\n",
    "        weightedRandomDirection= [d0*alphaBeta[0] + d1*alphaBeta[1] for (d0, d1) in zip(RD1,RD2)]\n",
    "        for (p, w, d) in zip(ae.parameters(), copy_of_the_weights, weightedRandomDirection):\n",
    "            p.data = w + d.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (images,labels) in enumerate(eval_data_loader):\n",
    "                images = to_var(images)\n",
    "                latentspace,_ = ae(images) #Forward propagation\n",
    "                \n",
    "                meanByLatentSize=latentspace.mean(axis=0)               \n",
    "                for j in range(latent_size):\n",
    "                    latentComponentsLoss[j][col_value,index%number_of_points]=meanByLatentSize[j]\n",
    "\n",
    "                latentComponentsMeanLoss[col_value,index%number_of_points]=meanByLatentSize.mean()\n",
    "                \n",
    "                L2norm=torch.norm(latentspace, dim=0)\n",
    "                for k in range(latent_size):\n",
    "                    latentComponentsLossL2[k][col_value,index%number_of_points]=L2norm[k]\n",
    "\n",
    "                latentComponentsMeanLossL2[col_value,index%number_of_points]=L2norm.mean()\n",
    "                   \n",
    "                temp=index+1\n",
    "                if temp%number_of_points==0:\n",
    "                    col_value=col_value+1\n",
    "                break\n",
    "        \n",
    "               \n",
    "    return latentComponentsMeanLoss,latentComponentsLoss,latentComponentsMeanLossL2,latentComponentsLossL2\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plots are saved in HTML format. You can hover over plots and get the coordinates,latent components value\n",
    "#https://plotly.com/python/interactive-html-export/\n",
    "    \n",
    "# orca can be used to save the plots in png or jpg format. \n",
    "#https://plotly.com/python/static-image-export/ \n",
    "\n",
    "\n",
    "\n",
    "def plotLatentLandscape(location,digits,data):\n",
    "    fig = make_subplots(rows=2, cols=4)\n",
    "    for i in range(8):    \n",
    "        fig.add_trace(\n",
    "            go.Contour(z=data[i],x=xcoordinates,y=ycoordinates),\n",
    "            row=i//4+1, col=i%4+1\n",
    "        )\n",
    "    fig.update_layout(height=550, width=1000, title_text=\"Latent Landscape for digit \"+str(digits))\n",
    "    path=location+\"/digit_\"+str(digits)+\".html\"\n",
    "    fig.write_html(path)\n",
    "    fig.show()\n",
    "    print(\"Plot saved to: \", path)\n",
    "    \n",
    "\n",
    "def plotlatentLandscapeMean(location,digits,data):\n",
    "    fig = go.Figure(data =\n",
    "    go.Contour(z=data,x=xcoordinates,y=ycoordinates))\n",
    "    fig.update_layout(height=400, width=500, title_text=\"Latent Landscape for digit \"+str(digits))\n",
    "    path=location+\"/digit_\"+str(digits)+\".html\"\n",
    "    fig.write_html(path)\n",
    "    \n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "direction1=get_random_weights_filter_norm(copy_of_the_weights)\n",
    "direction2=get_random_weights_filter_norm(copy_of_the_weights)\n",
    "plotsByDigits=[]\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"computing latent landscape for digit: \",i)\n",
    "    dataset_eval.targets = targetByDigits[i]\n",
    "    dataset_eval.data = dataByDigits[i]\n",
    "    eval_data_loader = torch.utils.data.DataLoader(dataset=dataset_eval,batch_size=60000,shuffle=True)\n",
    "    plotsByDigits.append(evalRandDirection(direction1,direction2))\n",
    "    print(\"Done\")\n",
    "\n",
    "with open('plotsByDigits.pkl', 'wb') as f:\n",
    "    pickle.dump(plotsByDigits, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('plotsByDigits.pkl', 'rb') as f:\n",
    "    plotsByDigits = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLocation=\"latentLanscapes_seed0\"\n",
    "if not os.path.exists(plotLocation):\n",
    "    os.mkdir(plotLocation)\n",
    "for i in range(10):\n",
    "    plotLatentLandscape(plotLocation,i,plotsByDigits[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotLocation=\"latentLanscapesMean_seed0\"\n",
    "#if not os.path.exists(plotLocation):\n",
    "#    os.mkdir(plotLocation)\n",
    "#for i in range(10):\n",
    "#    plotlatentLandscapeMean(plotLocation,i,plotsByDigits[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "direction1_seed1=get_random_weights_filter_norm(copy_of_the_weights)\n",
    "direction2_seed1=get_random_weights_filter_norm(copy_of_the_weights)\n",
    "plotsByDigits_seed1=[]\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"computing latent landscape for digit: \",i)\n",
    "    dataset_eval.targets = targetByDigits[i]\n",
    "    dataset_eval.data = dataByDigits[i]\n",
    "    eval_data_loader = torch.utils.data.DataLoader(dataset=dataset_eval,batch_size=60000,shuffle=True)\n",
    "    plotsByDigits_seed1.append(evalRandDirection(direction1_seed1,direction2_seed1))\n",
    "    print(\"Done\")\n",
    "\n",
    "with open('plotsByDigits_seed1.pkl', 'wb') as f:\n",
    "    pickle.dump(plotsByDigits_seed1, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('plotsByDigits_seed1.pkl', 'rb') as f:\n",
    "    plotsByDigits_seed1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLocation=\"latentLanscapes_seed1\"\n",
    "if not os.path.exists(plotLocation):\n",
    "    os.mkdir(plotLocation)\n",
    "    \n",
    "for i in range(10):\n",
    "    plotLatentLandscape(plotLocation,i,plotsByDigits_seed1[i][1])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "d1=get_random_weights(copy_of_the_weights)\n",
    "d2=get_random_weights(copy_of_the_weights)\n",
    "plotsByDigitsLayerNorm=[]\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"computing latent landscape for digit: \",i)\n",
    "    dataset_eval.targets = targetByDigits[i]\n",
    "    dataset_eval.data = dataByDigits[i]\n",
    "    eval_data_loader = torch.utils.data.DataLoader(dataset=dataset_eval,batch_size=60000,shuffle=True)\n",
    "    plotsByDigitsLayerNorm.append(evalRandDirection(d1,d2))\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('plotsByDigitsLayerNorm_seed0.pkl', 'wb') as f:\n",
    "    pickle.dump(plotsByDigits_seed1, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('plotsByDigitsLayerNorm_seed0.pkl', 'rb') as f:\n",
    "    plotsByDigitsLayerNorm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLocation=\"latentLandscapes_layerNorm_seed0\"\n",
    "if not os.path.exists(plotLocation):\n",
    "    os.mkdir(plotLocation)\n",
    "    \n",
    "for i in range(10):\n",
    "    plotLatentLandscape(plotLocation,i,plotsByDigitsLayerNorm[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
